{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASPBLwuRS6fE",
        "outputId": "496032a1-5601-48e2-ccb5-9c0baeeaf761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.10.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (24.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install librosa numpy soundfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def spectrogram_to_audio(spectrogram, sr=22050, n_iter=32, hop_length=512, win_length=None):\n",
        "    \"\"\"\n",
        "    Convert a magnitude spectrogram back to an audio signal using the Griffin-Lim algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    - spectrogram: np.ndarray, the input magnitude spectrogram.\n",
        "    - sr: int, the sample rate of the original audio signal.\n",
        "    - n_iter: int, the number of iterations for phase reconstruction using Griffin-Lim.\n",
        "    - hop_length: int, the hop length used for the STFT.\n",
        "    - win_length: int or None, the window length used for the STFT. If None, it defaults to `n_fft`.\n",
        "\n",
        "    Returns:\n",
        "    - audio_signal: np.ndarray, the reconstructed audio signal.\n",
        "    \"\"\"\n",
        "    # Griffin-Lim algorithm to estimate phase given only the magnitude spectrogram\n",
        "    audio_signal = librosa.griffinlim(spectrogram, n_iter=n_iter, hop_length=hop_length, win_length=win_length)\n",
        "    return audio_signal\n",
        "\n",
        "def save_audio_to_wav(audio_signal, output_file_path, sr=22050):\n",
        "    \"\"\"\n",
        "    Save an audio signal to a WAV file.\n",
        "\n",
        "    Parameters:\n",
        "    - audio_signal: np.ndarray, the audio signal to save.\n",
        "    - output_file_path: str, the path to the output WAV file.\n",
        "    - sr: int, the sample rate of the audio signal.\n",
        "    \"\"\"\n",
        "    sf.write(output_file_path, audio_signal, sr)\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Load an example spectrogram (replace this with your spectrogram)\n",
        "    y, sr = librosa.load(librosa.example('trumpet'), sr=None)\n",
        "    S = np.abs(librosa.stft(y))\n",
        "\n",
        "    # Convert the spectrogram to audio\n",
        "    audio_signal = spectrogram_to_audio(S, sr=sr)\n",
        "\n",
        "    # Save the reconstructed audio to a WAV file\n",
        "    save_audio_to_wav(audio_signal, 'reconstructed_audio.wav', sr=sr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4w9Oj_lS-35",
        "outputId": "329adaae-f334-423d-bd62-0e30b7a1c9a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'sorohanro_-_solo-trumpet-06.ogg' from 'https://librosa.org/data/audio/sorohanro_-_solo-trumpet-06.ogg' to '/root/.cache/librosa'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def image_to_spectrogram(image_path):\n",
        "    \"\"\"\n",
        "    Load an image and convert it into a spectrogram.\n",
        "\n",
        "    Parameters:\n",
        "    - image_path: str, the path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    - spectrogram: np.ndarray, the converted spectrogram.\n",
        "    \"\"\"\n",
        "    image = plt.imread(image_path)\n",
        "    # Assuming the image is in grayscale, normalize and convert to spectrogram scale\n",
        "    normalized_image = (image - image.min()) / (image.max() - image.min())\n",
        "    # Convert to amplitude spectrogram (assuming image represents dB scale)\n",
        "    spectrogram = librosa.db_to_amplitude(normalized_image * 80)\n",
        "    return spectrogram\n",
        "\n",
        "def spectrogram_to_audio(spectrogram, sr=22050, n_iter=32, hop_length=512, win_length=None):\n",
        "    \"\"\"\n",
        "    Convert a spectrogram back to an audio signal using the Griffin-Lim algorithm.\n",
        "    \"\"\"\n",
        "    # Determine n_fft as twice the spectrogram rows minus 2\n",
        "    n_fft = (spectrogram.shape[0] - 1) * 2\n",
        "\n",
        "    # Adjust hop_length if not specified\n",
        "    if hop_length is None:\n",
        "        hop_length = n_fft // 4\n",
        "\n",
        "    audio_signal = librosa.griffinlim(spectrogram, n_iter=n_iter, hop_length=hop_length, win_length=win_length)\n",
        "    return audio_signal\n",
        "\n",
        "def save_audio_to_wav(audio_signal, output_file_path, sr=22050):\n",
        "    \"\"\"\n",
        "    Save an audio signal to a WAV file.\n",
        "    \"\"\"\n",
        "\n",
        "    sf.write(output_file_path, audio_signal, sr)\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = '/content/test_gray.jpeg'  # Path to your spectrogram image\n",
        "    output_path = '/content/reconstructed_audio.wav'\n",
        "\n",
        "    # Convert the image to a spectrogram\n",
        "    spectrogram = image_to_spectrogram(image_path)\n",
        "\n",
        "    # Convert the spectrogram to audio\n",
        "    audio_signal = spectrogram_to_audio(spectrogram)\n",
        "\n",
        "    # Save the reconstructed audio to a WAV file\n",
        "    save_audio_to_wav(audio_signal, output_path)\n"
      ],
      "metadata": {
        "id": "6qwUSueOVIjd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def image_to_spectrogram(image_path):\n",
        "    # Load the image\n",
        "    image = plt.imread(image_path)\n",
        "    if len(image.shape) == 3:  # If the image is RGB\n",
        "        # Convert to grayscale\n",
        "        image = np.mean(image[..., :3], axis=2)\n",
        "    # Normalize the grayscale image to convert pixel values to spectrogram magnitudes\n",
        "    min_level_db = -100\n",
        "    ref_level_db = 20\n",
        "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "    # Convert to amplitude spectrogram\n",
        "    spectrogram = librosa.db_to_amplitude(normalized_image * (ref_level_db - min_level_db) + min_level_db)\n",
        "    return spectrogram\n",
        "\n",
        "\n",
        "def griffin_lim(spectrogram, sr=22050, n_iter=100, hop_length=512, win_length=1024):\n",
        "    # Perform the Griffin-Lim algorithm to reconstruct the audio signal from the amplitude spectrogram\n",
        "    n_fft = (spectrogram.shape[0] - 1) * 2\n",
        "    audio = librosa.griffinlim(spectrogram, n_iter=n_iter, hop_length=hop_length, win_length=win_length, n_fft=n_fft)\n",
        "    return audio\n",
        "\n",
        "def save_audio(audio, sr, file_path):\n",
        "    # Save the audio signal to a file\n",
        "    sf.write(file_path, audio, sr)\n",
        "\n",
        "# File paths\n",
        "image_path = '/content/test_gray.jpeg'\n",
        "output_wav_path = '/content/output_audio.wav'\n",
        "\n",
        "# Convert the image to a spectrogram\n",
        "spectrogram = image_to_spectrogram(image_path)\n",
        "\n",
        "# Perform phase reconstruction using the Griffin-Lim algorithm\n",
        "audio_signal = griffin_lim(spectrogram)\n",
        "\n",
        "# Save the audio signal to a .wav file\n",
        "save_audio(audio_signal, sr=22050, file_path=output_wav_path)\n"
      ],
      "metadata": {
        "id": "Vy2ePYLeeNPR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def image_to_spectrogram(image_path, n_fft, hop_length):\n",
        "    # Load the image (possibly in color)\n",
        "    image = plt.imread(image_path)\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:  # Check if the image is in color\n",
        "        # Convert to grayscale by averaging the RGB channels\n",
        "        image = np.mean(image, axis=-1)\n",
        "    # Assuming the grayscale image represents a linear magnitude spectrogram in dB scale\n",
        "    image = np.clip(image, 0, 1)  # Ensure the values are within [0, 1] range\n",
        "    spectrogram = librosa.db_to_amplitude(image * 80)  # Assuming the image represents dB values\n",
        "    return spectrogram\n",
        "\n",
        "def griffin_lim(spectrogram, sr, hop_length, win_length, n_iter=100):\n",
        "    # Reconstruct the audio signal from the amplitude spectrogram\n",
        "    n_fft = (spectrogram.shape[0] - 1) * 2\n",
        "    audio_reconstructed = librosa.griffinlim(spectrogram, n_iter=n_iter, hop_length=hop_length, win_length=win_length, n_fft=n_fft)\n",
        "    return audio_reconstructed\n",
        "\n",
        "def save_audio_to_wav(audio, sr, file_path):\n",
        "    # Save the audio signal to a WAV file\n",
        "    sf.write(file_path, audio, sr)\n",
        "\n",
        "# Adjust these parameters as necessary\n",
        "sr = 44100  # Replace with the actual sample rate if known\n",
        "n_fft = 512\n",
        "hop_length = 64  # 25% of the window size\n",
        "win_length = 256\n",
        "\n",
        "# Load the spectrogram image\n",
        "image_path = '/content/test_gray.jpeg'  # Update with the actual path to your spectrogram image\n",
        "spectrogram = image_to_spectrogram(image_path, n_fft, hop_length)\n",
        "\n",
        "# Perform phase reconstruction using the Griffin-Lim algorithm\n",
        "audio_signal = griffin_lim(spectrogram, sr=sr, hop_length=hop_length, win_length=win_length)\n",
        "\n",
        "# Save the audio signal to a WAV file\n",
        "output_wav_path = '/content/output_audio.wav'  # Update with the desired output path\n",
        "save_audio_to_wav(audio_signal, sr=sr, file_path=output_wav_path)\n"
      ],
      "metadata": {
        "id": "7QV1tP2micPh"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}